---
title: "Image Safeguarding: Reasoning with Conditional Vision Language Model and Obfuscating Unsafe Content Counterfactually"
collection: publications
permalink: /publication/2024-05-11-DTwin-TEC
excerpt: 'Keywords: Image Safeguarding'
date: 2024-01-19
venue: 'arXiv'
paperurl: 'https://pdf.sciencedirectassets.com/782866/1-s2.0-S2199853124X00025/1-s2.0-S219985312400091X/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAoaCXVzLWVhc3QtMSJGMEQCIDWK5To1%2BDTxMCaUHUgAkgwgmTf1GG9OgmC%2FpdMKtHjPAiA2THzMypcBxRRpQNDom19mO7gipIXQ9gmTXPijWgWeUCq7BQiS%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAUaDDA1OTAwMzU0Njg2NSIMAdsn%2BuWWDexmND8NKo8FZFq%2B8PUHErAgjlMqU3ahUdFoUZhapmmrXS8eRetScjTVn8FscLC%2FGa27L66f1JVMLpJwj35WtJExqLpnmQ4UEWUjWDeQEyNcLjIf3io4ES%2FspbiZRnlDF1ydrr3Vpl3j4igk6wACoe46NcNDZ53wXLYJ002gzZWRb0758onkPYtPJY2lNmfljcB9POt9F83Lxd8%2FCaV7ShsQi6MeB0l1M0nVUMeQ%2BTEa1sdaUmpTtCzjKBe40Op%2FA0Ti8KxHhMiAgJloljasgEYUre2RBVCxVLtzKWudqd3yu%2BLpxnuUdlzEyBj8s7KDSUbAPjfWutkIBEYThrLxzreTC%2BY6N62sQMEpo8iya5jmIWUroHJL%2FGQgcfO%2BGLiPRPjz4LwDMhl4MDSZanyG2VN2fsJmW0Vq3I5hRLKVbZPE3IBnwJsywrlPa2CRCJklsmwWMUi7Wp7zQlI0o4UprakVZdPxUOUwmQ9s7YHrG%2B6%2BM91tWXEI%2FjlBviUhLVjqLISqQx9DhjcPL3YijX%2BNef%2BWJzQsTjH43voG1bSsVxE5I%2Fim6soXkPtKqHbjPkncSveqsRVaLtrOVFo1FeJ1xoqxYUSR4Kf%2BrcD%2F3LLMpkrSNe8opGEgjKLxoRV%2BgiBfZU04zdNckIrZHeeo0JxYYSNcOkSL4ObDUcP7%2B8RLUFbe7uvtX73xMSlEJE%2FUiztNB4knPbZQBUM55Kd3l%2F5SIbMp1Rw9Gw4qcMKnteFaY6j2Mdimh4lrVUYMC%2BeVO9MMQ59rjOox66Y7a6WBMYUYPLpM0BGCKiyTfl7x7jFFA5cqhm93hzH%2FNHk866bwuqIBtxWa2CFaEkcsCSqrUj5l0UkWxft0N0C2LyT%2FCvqXXOkbCdStrfZI%2BTCi8feyBjqyAVHsZM1zqvrmfLF3AD3KHhyJa8ObnDAoxE9WRI1%2B2%2FnKEFAPTFTqWCAw8gTvBazXt%2FbS3Bu89tkxXjGriOh56A633OBtnYsMckc90srsk1Z3CRJ4ZoIzAgX2EztlqVhQQaTVXjLMr4G8TBIXPz3BaMWtZP4d9rgx9THC8E61cxbyl12%2FgTxsH5Ssnvf5M6hcMYcddCM26LpE0mfLHrw9VGBFbis5%2Bf1nPZ4RS4ixuajSZuM%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240603T175318Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYWFPBIA4I%2F20240603%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=8d04f571338aff7a02109e9cdf97b1ceaed8741de6ac71572e178c4e28238ef3&hash=2d0e861c21b240f0c6701c050358f13540535b4ffc23a49cc872e45193f04dc9&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S219985312400091X&tid=spdf-a0663bee-0997-4839-81a3-bd0398f25d18&sid=6e9dc55287625247562b561-9004f71f7dedgxrqa&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=1311565601515f010057&rr=88e18ab9ad040c13&cc=us'
# citation: 'Mohammad Saif Wajid, Hugo Terashima-Marin, Peyman Najafirad, Santiago Enrique Conant Pablos, Mohd Anas Wajid
# Abstract: The increasing popularity of digital twins, alongside the rapid evolution of connectivity driven by the Internet of Things, highlights their potential to greatly aid in the development of smart cities. Digital twins are employed more commonly as smart cities grow and societies become more interconnected. With the growing need for this technology, there is a pressing demand for the automatic captioning of security events from the videos collected from these models. This is needed as Dtwin models generate a lot of data that makes it difficult to caption them manually. This is required for extracting rich and meaningful higher-level interpretations from images and videos. Current models often lack in-depth insights into these complex urban systems. Additionally, there is a need for a model that can interpret and explain images and videos effectively, leveraging a combination of machine learning and knowledge graph approaches. Therefore, in this paper, we developed the Digital Twin for the buildings and road network of the TEC (Tecnologico De Monterrey) district region and additionally developed the Knowledge Graph models for emulating security events with dense video captioning. This is done by designing an AI-based TEC District Digital Twin for emulating security events by leveraging knowledge graph. The proposed approach provides data and insights about the district’s operations and security. This initiative will help district planners and managers to make better decisions by analyzing the real-time data. This is supposed to contribute to increased effectiveness of district services, transparency, and an efficient infrastructure.
# Keywords: Image Safeguarding'
---

# Abstract
Social media platforms are being increasingly used by malicious actors to share unsafe content, such as images depicting sexual activity, cyberbullying, and self-harm. Consequently, major platforms use artificial intelligence (AI) and human moderation to obfuscate such images to make them safer. Two critical needs for obfuscating unsafe images is that an accurate rationale for obfuscating image regions must be provided, and the sensitive regions should be
obfuscated (e.g. blurring) for users’ safety. This process involves addressing two key problems: (1) the reason for obfuscating unsafe images demands the platform to provide an accurate rationale that must be grounded in unsafe imagespecific attributes, and (2) the unsafe regions in the image
must be minimally obfuscated while still depicting the safe regions. In this work, we address these key issues by first performing visual reasoning by designing a visual reasoning model (VLM) conditioned on pre-trained unsafe image
classifiers to provide an accurate rationale grounded in unsafe image attributes, and then proposing a counterfactual explanation algorithm that minimally identifies and obfuscates unsafe regions for safe viewing, by first utilizing an unsafe image classifier attribution matrix to guide segmentation for a more optimal subregion segmentation followed
by an informed greedy search to determine the minimum number of subregions required to modify the classifier’s output based on attribution score. Extensive experiments on uncurated data from social networks emphasize the efficacy
of our proposed method. We make our code available at:
https://github.com/SecureAIAutonomyLab/ConditionalVLM
[Download paper here](https://arxiv.org/pdf/2401.11035)
