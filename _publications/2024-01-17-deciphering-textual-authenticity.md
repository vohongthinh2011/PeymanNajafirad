---
title: "Deciphering Textual Authenticity: A Generalized Strategy through the Lens of Large Language Semantics for Detecting Human vs. Machine-Generated Text"
collection: publications
permalink: /publication/2024-01-17-deciphering-textual-authenticity
excerpt: 'Keywords:  Large Language Models'
date: 2024-04-01
venue: 'arXiv'
paperurl: 'https://arxiv.org/pdf/2401.09407'
# citation: 'Mohammad Saif Wajid, Hugo Terashima-Marin, Peyman Najafirad, Santiago Enrique Conant Pablos, Mohd Anas Wajid
# Abstract: The increasing popularity of digital twins, alongside the rapid evolution of connectivity driven by the Internet of Things, highlights their potential to greatly aid in the development of smart cities. Digital twins are employed more commonly as smart cities grow and societies become more interconnected. With the growing need for this technology, there is a pressing demand for the automatic captioning of security events from the videos collected from these models. This is needed as Dtwin models generate a lot of data that makes it difficult to caption them manually. This is required for extracting rich and meaningful higher-level interpretations from images and videos. Current models often lack in-depth insights into these complex urban systems. Additionally, there is a need for a model that can interpret and explain images and videos effectively, leveraging a combination of machine learning and knowledge graph approaches. Therefore, in this paper, we developed the Digital Twin for the buildings and road network of the TEC (Tecnologico De Monterrey) district region and additionally developed the Knowledge Graph models for emulating security events with dense video captioning. This is done by designing an AI-based TEC District Digital Twin for emulating security events by leveraging knowledge graph. The proposed approach provides data and insights about the district’s operations and security. This initiative will help district planners and managers to make better decisions by analyzing the real-time data. This is supposed to contribute to increased effectiveness of district services, transparency, and an efficient infrastructure.
# Keywords: Digital Twin; Smart District; Artificial Intelligence; Knowledge Graph; Dense Captioning'
---

# Abstract
With the recent proliferation of Large Language Models (LLMs), there has been an increasing demand for tools to detect machine-generated text. The effective detection of machine-generated text face two pertinent problems: First, they are severely limited in generalizing against real-world scenarios, where machine-generated text is produced by a variety of generators and spans diverse domains. Second, existing detection methodologies treat texts produced by LLMs through a restrictive binary classification lens, neglecting the nuanced diversity of artifacts generated by different LLMs, each of which exhibits distinctive stylistic and structural elements. In this work, we undertake a systematic study on the detection of machine-generated text in real-world scenarios. We first study the effectiveness of state-of-the-art approaches and find that they are severely limited against text produced by diverse generators and domains in the real world. Furthermore, t-SNE visualizations of the embeddings from a pretrained LLM’s encoder show that they cannot reliably distinguish between human and machine-generated text. Based on our findings, we introduce a novel system, T5LLMCipher, for detecting machine-generated text using a pretrained T5 encoder combined with LLM embedding sub-clustering to address the text produced by diverse generators and domains in the real world. We evaluate our approach across 9 machine-generated text systems and 9 domains and find that our approach provides state-of-the-art generalization ability, with an average increase in F1 score on machine-generated text of 11.9% on unseen generators and domains compared to the top performing supervised learning approaches and correctly attributes the generator of text with an accuracy of 93.6%. We make the code for our proposed approach publicly available at https://github.com/SecureAIAutonomyLab/LLM-Cipher

[Download paper here](https://arxiv.org/pdf/2401.09407)
